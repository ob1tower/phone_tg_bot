import random
import os
import uuid
import nltk
from gtts import gTTS
from pydub import AudioSegment
import speech_recognition as sr
from telegram import Update
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    ContextTypes, filters
)
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer
from natasha import Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger, Doc
from nltk.metrics import edit_distance

# --- Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ NLP ---
nltk.download('punkt')
segmenter = Segmenter()
emb = NewsEmbedding()
morph_vocab = MorphVocab()
morph_tagger = NewsMorphTagger(emb)

# --- ÐšÐ¾Ð½Ñ„Ð¸Ð³ Ð±Ð¾Ñ‚Ð° ---
BOT_CONFIG = {
    'intents': {
        'greeting': {
            'examples': ['Ð¿Ñ€Ð¸Ð²ÐµÑ‚', 'Ð·Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹', 'ÑÑ‚Ð°Ñ€Ñ‚', 'Ð´Ð¾Ð±Ñ€Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ'],
            'responses': ['Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ?']
        },
        'goodbye': {
            'examples': ['Ð¿Ð¾ÐºÐ°', 'Ð´Ð¾ ÑÐ²Ð¸Ð´Ð°Ð½Ð¸Ñ', 'ÑƒÐ²Ð¸Ð´Ð¸Ð¼ÑÑ'],
            'responses': ['Ð”Ð¾ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð¸! Ð—Ð°Ñ…Ð¾Ð´Ð¸Ñ‚Ðµ ÐµÑ‰Ñ‘.']
        }
    },
    'failure_phrases': [
        'ÐÐµ ÑÐ¾Ð²ÑÐµÐ¼ Ð¿Ð¾Ð½ÑÐ», Ð¼Ð¾Ð¶ÐµÑ‚Ðµ ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸Ñ‚ÑŒ?',
        'ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ.',
        'Ð¯ ÐµÑ‰Ñ‘ ÑƒÑ‡ÑƒÑÑŒ, Ð½Ð¾ ÑÑ‚Ð°Ñ€Ð°ÑŽÑÑŒ Ð¿Ð¾Ð½ÑÑ‚ÑŒ Ð²Ð°Ñ.'
    ],
    'products': [
        {
            'name': 'iPhone 15 Pro',
            'keywords': ['ÑÐ±Ð»Ð¾ÐºÐ¾', 'Ð°Ð¹Ñ„Ð¾Ð½', 'iphone'],
            'price': '129â€¯990â€¯â‚½',
            'desc': 'Ð¢Ð¸Ñ‚Ð°Ð½, ÐºÐ°Ð¼ÐµÑ€Ð° 48â€¯ÐœÐ¿'
        },
        {
            'name': 'Samsung Galaxy S24',
            'keywords': ['ÑÐ°Ð¼ÑÑƒÐ½Ð³', 'Ð³Ð°Ð»Ð°ÐºÑÐ¸', 'android'],
            'price': '89â€¯990â€¯â‚½',
            'desc': 'Ð­ÐºÑ€Ð°Ð½ 144â€¯Ð“Ñ†'
        },
        {
            'name': 'Xiaomi Redmi Note 13',
            'keywords': ['ÐºÑÐ¸Ð°Ð¾Ð¼Ð¸', 'Ñ€ÐµÐ´Ð¼Ð¸', 'Ð±ÑŽÐ´Ð¶ÐµÑ‚Ð½Ñ‹Ð¹'],
            'price': '24â€¯990â€¯â‚½',
            'desc': 'AMOLED ÑÐºÑ€Ð°Ð½'
        }
    ]
}

# Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ ÑÐ¼Ð¾Ñ†Ð¸Ð¹
emo_dict = {
    'Ð»ÑŽÐ±Ð»ÑŽ': 1, 'Ð¾Ð±Ð¾Ð¶Ð°ÑŽ': 1, 'ÑÑƒÐ¿ÐµÑ€': 1, 'Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾': 1, 'ÑÑ‡Ð°ÑÑ‚Ð»Ð¸Ð²': 1,
    'Ð½ÐµÐ½Ð°Ð²Ð¸Ð¶Ñƒ': -1, 'ÑƒÐ¶Ð°Ñ': -1, 'Ð¿Ð»Ð¾Ñ…Ð¾': -1, 'Ð³Ñ€ÑƒÑÑ‚ÑŒ': -1, 'Ð·Ð»ÑŽÑÑŒ': -1,
    'Ð½Ñ€Ð°Ð²Ð¸Ñ‚ÑÑ': 1, 'Ð¿ÐµÑ‡Ð°Ð»ÑŒÐ½Ð¾': -1, 'Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾': 0, 'Ñ‚Ð°ÐºÐ¾Ðµ': 0,
}

# --- Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð² ---
def load_dialogues():
    out = []
    try:
        with open('dialogues.txt', 'r', encoding='utf-8') as f:
            for block in f.read().split('\n\n'):
                parts = block.strip().split('\n')
                if len(parts) >= 2:
                    out.append((parts[0].strip(), parts[1].strip()))
    except FileNotFoundError:
        pass
    return out


dialogues = load_dialogues()

# --- ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð° Ð½Ð°Ð¼ÐµÑ€ÐµÐ½Ð¸Ð¹ ---
X_text, y = [], []
for intent, data in BOT_CONFIG['intents'].items():
    X_text += data['examples']
    y += [intent] * len(data['examples'])

vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3, 3))
X = vectorizer.fit_transform(X_text)
clf = LinearSVC().fit(X, y)

# --- NLPâ€‘Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ ---
def clean_text(text: str) -> str:
    return ''.join(c for c in text.lower() if c.isalpha() or c == ' ').strip()


def lemmatize(text: str) -> str:
    doc = Doc(text)
    doc.segment(segmenter)
    doc.tag_morph(morph_tagger)
    for tok in doc.tokens:
        tok.lemmatize(morph_vocab)
    return ' '.join(tok.lemma for tok in doc.tokens)


def analyze_sentiment(text: str) -> str:
    s = sum(emo_dict.get(w, 0) for w in text.split())
    return 'Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹' if s > 0 else 'Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹' if s < 0 else 'Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹'


def classify_intent(text: str) -> dict:
    lem = lemmatize(text)
    for p in BOT_CONFIG['products']:
        if any(k in lem for k in p['keywords']):
            return {'type': 'product', 'data': p}
    intent = clf.predict(vectorizer.transform([clean_text(text)]))[0]
    return {'type': 'intent', 'data': intent}


def generate_answer(text: str) -> str:
    t = clean_text(text)
    t_words = set(t.split())
    for q, a in dialogues:
        qc = clean_text(q)
        qc_words = set(qc.split())
        if qc_words <= t_words:
            return a
        if edit_distance(t, qc) / max(len(qc), 1) < 0.4:
            return a
    return None

# --- ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ Ñ€ÐµÐ¶Ð¸Ð¼Ð° ---
async def send_response(update: Update, context: ContextTypes.DEFAULT_TYPE, text: str):
    mode = context.user_data.get('response_mode', 'text')
    if mode == 'voice':
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ñ‡ÐµÑ€ÐµÐ· gTTS
        path = f"tts_{uuid.uuid4()}.mp3"
        try:
            gTTS(text, lang='ru').save(path)
            await update.message.reply_voice(voice=open(path, 'rb'))
        finally:
            if os.path.exists(path):
                os.remove(path)
    else:
        await update.message.reply_text(text)

# --- ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ ---
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE, *, recognized_text: str = None):
    text_raw = recognized_text or update.message.text or ""
    text = clean_text(text_raw)

    # Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ¶Ð¸Ð¼Ð¾Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
    if text in ['Ð³Ð¾Ð»Ð¾ÑÐ¾Ð¼', 'Ð³Ð¾Ð»Ð¾Ñ']:
        context.user_data['response_mode'] = 'voice'
        await send_response(update, context, "ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ð»ÑÑ Ð½Ð° Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹.")
        return
    elif text in ['Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼', 'Ñ‚ÐµÐºÑÑ‚']:
        context.user_data['response_mode'] = 'text'
        await send_response(update, context, "ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ð»ÑÑ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹.")
        return

    # 0. Ð¡Ð¿ÐµÑ†-Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Â«ÐºÐ°Ðº Ð´ÐµÐ»Ð°Â»
    if 'Ð´ÐµÐ»Ð°' in text and ('ÐºÐ°Ðº' in text or 'Ñƒ Ñ‚ÐµÐ±Ñ' in text):
        await send_response(update, context, "Ð£ Ð¼ÐµÐ½Ñ Ð²ÑÑ‘ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾! Ð Ñƒ Ð²Ð°Ñ ÐºÐ°Ðº?")
        return

    # 1. ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    tone = analyze_sentiment(text)
    await send_response(update, context, f"ðŸ” Ð¢Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: {tone}")

    # 2. ÐžÑ‚Ð²ÐµÑ‚ Ð¿Ð¾ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°Ð¼ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°
    answer = generate_answer(text)
    if answer:
        await send_response(update, context, answer)
        return

    # 3. ÐŸÑ€ÑÐ¼Ð¾Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð² Ð¿Ð¾ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ð¼ ÑÐ»Ð¾Ð²Ð°Ð¼
    if any(word in text for word in ['Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½', 'ÑÐ¼Ð°Ñ€Ñ‚Ñ„Ð¾Ð½', 'Ð¼Ð¾Ð´ÐµÐ»', 'Ð¿Ð¾ÐºÐ°Ð¶Ð¸', 'Ð½Ð¾Ð²Ð¸Ð½Ðº']):
        await show_products(update, context)
        return

    # 4. ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Â«Ð´Ð°/Ð½ÐµÑ‚Â» Ð¿Ð¾ÑÐ»Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
    if context.user_data.get('last_intent') == 'offer_products':
        if text in ['Ð´Ð°', 'Ñ…Ð¾Ñ‡Ñƒ']:
            await show_products(update, context)
            return
        elif text in ['Ð½ÐµÑ‚', 'Ð½Ðµ Ñ…Ð¾Ñ‡Ñƒ']:
            context.user_data['last_intent'] = None
            await send_response(update, context, "ÐŸÐ¾Ð½ÑÑ‚Ð½Ð¾. Ðž Ñ‡Ñ‘Ð¼ ÐµÑ‰Ñ‘ Ð¿Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ð¼?")
            return

    # 5. ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ: Ñ‚Ð¾Ð²Ð°Ñ€Ñ‹ Ð¸Ð»Ð¸ intent
    intent = classify_intent(text)
    if intent['type'] == 'product':
        product = intent['data']
        context.user_data['selected'] = product
        context.user_data['last_intent'] = 'offer_products'
        await send_response(update, context,
                            f"ðŸ”¹ {product['name']} â€” {product['desc']}\nÐ¦ÐµÐ½Ð°: {product['price']}\nÐÐ°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ Â«Ð¾Ñ„Ð¾Ñ€Ð¼Ð¸Ñ‚ÑŒÂ», Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð·Ð°ÐºÐ°Ð·Ð°Ñ‚ÑŒ."
                            )
        return
    elif intent['type'] == 'intent':
        response = random.choice(
            BOT_CONFIG['intents'][intent['data']]['responses'])
        context.user_data['last_intent'] = intent['data']
        await send_response(update, context, response)
        return

    # 6. ÐžÑ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð¸Ðµ Ð·Ð°ÐºÐ°Ð·Ð°
    if text == 'Ð¾Ñ„Ð¾Ñ€Ð¼Ð¸Ñ‚ÑŒ' and context.user_data.get('selected'):
        product = context.user_data['selected']
        context.user_data.clear()
        await send_response(update, context, f"âœ… Ð—Ð°ÐºÐ°Ð· Ð½Ð° {product['name']} Ð¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½. Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾!")
        return

    # 7. Ð¤Ð¾Ð»Ð»Ð±ÐµÐº-Ð¾Ñ‚Ð²ÐµÑ‚
    await send_response(update, context, random.choice(BOT_CONFIG['failure_phrases']))


# --- ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ ---
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    ogg_path = wav_path = None
    try:
        voice_file = await update.message.voice.get_file()
        ogg_path = f"voice_{uuid.uuid4()}.ogg"
        await voice_file.download_to_drive(ogg_path)

        audio = AudioSegment.from_ogg(ogg_path)
        wav_path = ogg_path.replace('.ogg', '.wav')
        audio.export(wav_path, format='wav')

        recognizer = sr.Recognizer()
        with sr.AudioFile(wav_path) as src:
            data = recognizer.record(src)
            text = recognizer.recognize_google(data, language='ru-RU')

        await send_response(update, context, f"ðŸ—£ Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¾: {text}")
        await handle_text(update, context, recognized_text=text)

    except Exception as e:
        await send_response(update, context, f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ: {e}")

    finally:
        for path in (ogg_path, wav_path):
            if path and os.path.exists(path):
                os.remove(path)

# --- ÐšÐ¾Ð¼Ð°Ð½Ð´Ñ‹ ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    context.user_data['last_intent'] = None
    context.user_data['response_mode'] = 'text'
    await update.message.reply_text(
        "ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ Ð±Ð¾Ñ‚. ÐÐ°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ.\n"
        "ÐšÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ñ€ÐµÐ¶Ð¸Ð¼Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n"
        "- Ð³Ð¾Ð»Ð¾ÑÐ¾Ð¼\n"
        "- Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼"
    )

# --- ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð·Ð¸Ñ‚ÑŒ Ñ‚Ð¾Ð²Ð°Ñ€Ñ‹ ---
async def show_products(update: Update, context: ContextTypes.DEFAULT_TYPE):
    lines = ["Ð’Ð¾Ñ‚ Ð½Ð°ÑˆÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ð¾Ð²:"]
    for p in BOT_CONFIG['products']:
        lines.append(f"â€¢ {p['name']}: {p['desc']} â€” {p['price']}")
    lines.append(
        "ÐÐ°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸, Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑƒÐ·Ð½Ð°Ñ‚ÑŒ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ÑÑ‚Ð¸, Ð¸Ð»Ð¸ Â«Ð¾Ñ„Ð¾Ñ€Ð¼Ð¸Ñ‚ÑŒÂ» Ð´Ð»Ñ Ð·Ð°ÐºÐ°Ð·Ð°.")
    await send_response(update, context, '\n'.join(lines))
    context.user_data['last_intent'] = 'offer_products'

# --- Ð—Ð°Ð¿ÑƒÑÐº ---
if __name__ == '__main__':
    app = ApplicationBuilder().token(
        '7995703622:AAHcpbmNiv70ZoM3te69qiUZdEZhlHv8Drk').build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(
        filters.TEXT & (~filters.COMMAND), handle_text))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    print("Bot started")
    app.run_polling()
